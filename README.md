# AI in Education - Uzbek STT & Attendance System

Complete AI-powered system for education featuring speech-to-text and automatic face recognition attendance for Uzbek schools.

## ðŸŽ¯ Features

### Speech-to-Text System
- **High-Accuracy STT**: XLS-R model (15.07% WER) for Uzbek speech recognition
- **Multiple Models**: XLS-R (primary), Whisper (backup), HF Pipeline (general)
- **Live Transcription**: Real-time speech-to-text from microphone
- **Text-to-Speech**: Natural Uzbek speech synthesis for educational content
- **Interactive Teaching**: AI-powered lessons combining STT and TTS
- **Accuracy Testing**: Comprehensive WER/CER metrics and reporting

### Face Recognition Attendance
- **Automatic Attendance**: FaceNet-based recognition at entrance camera
- **Student Enrollment**: Easy webcam or image-based enrollment
- **SQLite Database**: Local storage for students and attendance records
- **Real-time Processing**: ~100ms recognition per frame
- **Attendance Reports**: Daily, weekly, monthly statistics by class
- **Privacy-Focused**: Local processing, no cloud dependency

## ðŸ“ Project Structure

```
AI_in_Education/
â”œâ”€â”€ main.py                    # Main CLI entry point
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ stt_pipelines/            # Speech-to-Text modules
â”‚   â”œâ”€â”€ uzbek_xlsr_pipeline.py      # XLS-R (primary, 15% WER)
â”‚   â”œâ”€â”€ uzbek_whisper_pipeline.py   # Whisper (backup, 30% WER)
â”‚   â”œâ”€â”€ uzbek_hf_pipeline.py        # HuggingFace ASR
â”‚   â””â”€â”€ uzbek_tts_pipeline.py       # Text-to-Speech
â”‚
â”œâ”€â”€ face_recognition/         # Attendance system
â”‚   â”œâ”€â”€ face_recognition_db.py      # SQLite database
â”‚   â”œâ”€â”€ face_enrollment.py          # Student enrollment
â”‚   â””â”€â”€ face_attendance.py          # Real-time attendance
â”‚
â”œâ”€â”€ utils/                    # Utilities
â”‚   â”œâ”€â”€ uzbek_text_postprocessor.py
â”‚   â””â”€â”€ uzbek_accuracy_testing_framework.py
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ FACE_RECOGNITION_README.md
â”‚   â”œâ”€â”€ COMPLETE_SYSTEM_DOCS.md
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md
â”‚
â””â”€â”€ data/                     # Data files & reports
    â”œâ”€â”€ students.db           # SQLite database (runtime)
    â””â”€â”€ *.json                # Accuracy reports
```

## ðŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/umaraliyev0101/AI_for_Education.git
cd AI_in_Education

# Install dependencies
pip install -r requirements.txt
```

### STT Usage

```python
from stt_pipelines.uzbek_xlsr_pipeline import create_uzbek_xlsr_stt

# Create STT instance
stt = create_uzbek_xlsr_stt()

# Transcribe audio file
result = stt.transcribe_file("audio.wav")
print(result["text"])
```

### Command Line Usage

**STT Commands:**
```bash
# Run accuracy tests
python main.py test

# Transcribe audio file
python main.py transcribe audio.wav xlsr

# Live transcription from microphone
python main.py live

# Text-to-speech
python main.py speak "Salom, bolalar!"

# Interactive teaching mode
python main.py teach
```

**Attendance Commands:**
```bash
# Enroll new student
python main.py enroll

# Start entrance camera
python main.py attendance

# View attendance report
python main.py report

# List all students
python main.py students
```

### Face Recognition Setup

```python
from face_recognition.face_enrollment import FaceEnrollmentSystem
from face_recognition.face_recognition_db import FaceRecognitionDB

# Enroll student
enrollment = FaceEnrollmentSystem()
db = FaceRecognitionDB()

student_id, name, class_name, encoding = enrollment.enroll_student_interactive()
db.add_student(student_id, name, class_name, encoding)
```

## ðŸ“Š Model Performance

| Model | WER | CER | Language | Use Case |
|-------|-----|-----|----------|----------|
| XLS-R | 15.07% | 3.08% | Uzbek | Primary STT |
| Whisper | ~30-35% | ~8-10% | Uzbek | Backup STT |
| FaceNet | 99.3% | - | - | Face Recognition |

## ðŸ“š Documentation

- **[Complete System Docs](docs/COMPLETE_SYSTEM_DOCS.md)**: Full technical documentation
- **[Face Recognition Guide](docs/FACE_RECOGNITION_README.md)**: Attendance system usage
- **[Project Structure](docs/PROJECT_STRUCTURE.md)**: Detailed file organization

## ðŸ”§ Requirements

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.30+
- OpenCV 4.8+
- facenet-pytorch
- SQLite3 (included with Python)

## ðŸŽ“ Use Cases

1. **Classroom Attendance**: Automatic student attendance via entrance camera
2. **Uzbek Language Learning**: Interactive STT/TTS lessons
3. **Speech Recognition**: Transcribe Uzbek audio files
4. **Attendance Analytics**: Track student attendance patterns
5. **Educational Research**: Measure STT accuracy for Uzbek

## ðŸ¤ Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ðŸ‘¥ Authors

- **Umar Aliyev** - [GitHub](https://github.com/umaraliyev0101)

## ðŸ™ Acknowledgments

- XLS-R model by Meta AI
- Whisper model by OpenAI
- FaceNet by Google
- Uzbek speech data contributors
python main.py interactive
```

## Project Structure

```
â”œâ”€â”€ main.py                          # Main entry point
â”œâ”€â”€ uzbek_whisper_pipeline.py        # Core Whisper STT pipeline
â”œâ”€â”€ uzbek_tts_pipeline.py           # Text-to-speech pipeline
â”œâ”€â”€ uzbek_accuracy_testing_framework.py  # Testing and metrics
â”œâ”€â”€ uzbek_text_postprocessor.py      # Text post-processing
â”œâ”€â”€ uzbek_audio_preprocessor.py      # Audio preprocessing
â”œâ”€â”€ uzbek_pronunciation_dictionary.py # Pronunciation guide
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ docs/                           # Documentation
```

## Performance

- **Word Error Rate (WER)**: ~5%
- **Character Error Rate (CER)**: ~2%
- **Processing**: Real-time capable on modern hardware

## API Reference

### UzbekWhisperSTT

```python
class UzbekWhisperSTT:
    def transcribe_audio(audio_data, sample_rate=16000) -> Dict
    def transcribe_file(file_path) -> Dict
    def get_model_info() -> Dict
```

### UzbekTTSPipeline

```python
class UzbekTTSPipeline:
    def speak_text(text: str, save_to_file=None) -> bool
    def generate_speech(text: str) -> bytes
    def get_available_voices() -> Dict[str, str]
    def test_tts() -> bool
```

### UzbekAccuracyTester

```python
class UzbekAccuracyTester:
    def test_text_accuracy(test_cases, session_name=None) -> UzbekAccuracyReport
    def save_report(report, output_file=None)
    def print_summary(report)
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `python main.py test`
5. Submit a pull request

## License

MIT License - see LICENSE file for details
